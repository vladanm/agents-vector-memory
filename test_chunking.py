#!/usr/bin/env python3
"""
Comprehensive Chunking Validation Test
Tests 2-stage code-aware chunking implementation
"""

import sys
from pathlib import Path

# Run from within the package
from src.chunking import DocumentChunker, ChunkingConfig

def print_separator(title):
    """Print a section separator"""
    print(f"\n{'=' * 80}")
    print(f"  {title}")
    print(f"{'=' * 80}\n")

def analyze_chunks(chunks, test_name):
    """Analyze and report on chunk characteristics"""
    print_separator(f"Test Results: {test_name}")

    # Basic statistics
    total_chunks = len(chunks)
    token_counts = [c.token_count for c in chunks]
    total_tokens = sum(token_counts)

    print(f"üìä BASIC STATISTICS")
    print(f"  Total chunks: {total_chunks}")
    print(f"  Total tokens: {total_tokens}")
    print(f"  Avg chunk size: {total_tokens // total_chunks if total_chunks > 0 else 0} tokens")
    print(f"  Min size: {min(token_counts) if token_counts else 0} tokens")
    print(f"  Max size: {max(token_counts) if token_counts else 0} tokens")

    # Size distribution
    small_chunks = [c for c in chunks if c.token_count < 150]
    medium_chunks = [c for c in chunks if 150 <= c.token_count <= 800]
    large_chunks = [c for c in chunks if c.token_count > 800]

    print(f"\nüìà SIZE DISTRIBUTION")
    print(f"  Small (<150 tokens): {len(small_chunks)} ({len(small_chunks)/total_chunks*100:.1f}%)")
    print(f"  Medium (150-800): {len(medium_chunks)} ({len(medium_chunks)/total_chunks*100:.1f}%)")
    print(f"  Large (>800 tokens): {len(large_chunks)} ({len(large_chunks)/total_chunks*100:.1f}%)")

    # Code block analysis
    code_chunks = [c for c in chunks if '```' in c.content]
    balanced_code = []
    unbalanced_code = []

    for chunk in code_chunks:
        fence_count = chunk.content.count('```')
        if fence_count % 2 == 0:
            balanced_code.append(chunk)
        else:
            unbalanced_code.append(chunk)

    print(f"\nüîç CODE INTEGRITY")
    print(f"  Chunks with code: {len(code_chunks)}")
    print(f"  Balanced fences: {len(balanced_code)}")
    print(f"  Unbalanced fences: {len(unbalanced_code)}")

    if code_chunks:
        integrity_score = len(balanced_code) / len(code_chunks)
        print(f"  Integrity score: {integrity_score:.1%}")

        if integrity_score >= 0.95:
            print(f"  ‚úÖ PASSED: Code integrity meets target (‚â•95%)")
        else:
            print(f"  ‚ùå FAILED: Code integrity below target ({integrity_score:.1%} < 95%)")
    else:
        print(f"  ‚ö†Ô∏è  No code blocks found")

    # Metadata analysis
    chunks_with_metadata = [c for c in chunks if hasattr(c, 'metadata') and c.metadata]
    code_metadata = [c for c in chunks_with_metadata if c.metadata.get('is_code')]
    language_metadata = [c for c in chunks_with_metadata if c.metadata.get('language')]

    print(f"\nüìù METADATA ANALYSIS")
    print(f"  Chunks with metadata: {len(chunks_with_metadata)}")
    print(f"  Code chunks flagged: {len(code_metadata)}")
    print(f"  Language detected: {len(language_metadata)}")

    if language_metadata:
        languages = {}
        for chunk in language_metadata:
            lang = chunk.metadata.get('language', 'unknown')
            languages[lang] = languages.get(lang, 0) + 1

        print(f"  Languages found: {', '.join(f'{lang}({count})' for lang, count in languages.items())}")

    # Header structure
    chunks_with_headers = [c for c in chunks if hasattr(c, 'header_path') and c.header_path]

    print(f"\nüìÇ STRUCTURE ANALYSIS")
    print(f"  Chunks with headers: {len(chunks_with_headers)}")
    if chunks_with_headers:
        max_level = max(c.level for c in chunks_with_headers)
        print(f"  Max header depth: {max_level}")

    # Sample chunks
    print(f"\nüìÑ SAMPLE CHUNKS (first 3)")
    for i, chunk in enumerate(chunks[:3]):
        preview = chunk.content[:100].replace('\n', ' ')
        print(f"\n  Chunk {i}: {chunk.token_count} tokens")
        if hasattr(chunk, 'header_path') and chunk.header_path:
            print(f"    Header: {chunk.header_path}")
        if hasattr(chunk, 'metadata') and chunk.metadata:
            if chunk.metadata.get('is_code'):
                lang = chunk.metadata.get('language', 'unknown')
                print(f"    Code: {lang}")
        print(f"    Preview: {preview}...")

def test_code_heavy_document():
    """Test with code-heavy technical document"""
    print_separator("Test 1: Code-Heavy Technical Document")

    # Read test document
    doc_path = Path(__file__).parent.parent / "test_code_heavy_doc.md"
    if not doc_path.exists():
        print(f"‚ùå ERROR: Test document not found at {doc_path}")
        return False

    with open(doc_path, 'r') as f:
        content = f.read()

    print(f"üìñ Document loaded: {len(content)} characters")

    # Configure chunker for knowledge base
    config = ChunkingConfig(
        chunk_size=1000,
        chunk_overlap=100,
        preserve_structure=True,
        content_format='markdown',
        memory_type='knowledge_base'
    )

    chunker = DocumentChunker(config)

    # Chunk the document
    print("üîÑ Chunking document...")
    chunks = chunker.chunk_document(content, parent_id=1)

    # Analyze results
    analyze_chunks(chunks, "Code-Heavy Document (1000 tokens)")

    return True

def test_reports_configuration():
    """Test with reports configuration (larger chunks)"""
    print_separator("Test 2: Reports Configuration (1500 tokens)")

    doc_path = Path(__file__).parent.parent / "test_code_heavy_doc.md"
    with open(doc_path, 'r') as f:
        content = f.read()

    config = ChunkingConfig(
        chunk_size=1500,
        chunk_overlap=150,
        preserve_structure=True,
        content_format='markdown',
        memory_type='reports_store'
    )

    chunker = DocumentChunker(config)
    chunks = chunker.chunk_document(content, parent_id=2)

    analyze_chunks(chunks, "Reports Configuration (1500 tokens)")

    return True

def test_edge_cases():
    """Test specific edge cases"""
    print_separator("Test 3: Edge Cases")

    # Test 1: Code preceded by colon
    test_1 = """## Example

Here is the code:

```python
def hello():
    print("world")
```"""

    # Test 2: Nested code blocks
    test_2 = """## Documentation

````markdown
Example:

```python
x = 1
```
````"""

    # Test 3: Multiple languages
    test_3 = """## Multi-language

Python:

```python
x = 1
```

JavaScript:

```javascript
const x = 1;
```"""

    # Test 4: Oversized code block
    test_4 = "## Large Code\n\n```python\n" + ("# comment\n" * 200) + "```"

    test_cases = [
        ("Code with colon", test_1),
        ("Nested code blocks", test_2),
        ("Multiple languages", test_3),
        ("Oversized code block", test_4)
    ]

    config = ChunkingConfig(chunk_size=500, chunk_overlap=50)
    chunker = DocumentChunker(config)

    for name, content in test_cases:
        print(f"\n{'‚îÄ' * 80}")
        print(f"Edge Case: {name}")
        print(f"{'‚îÄ' * 80}")

        chunks = chunker.chunk_document(content, parent_id=100)

        # Quick analysis
        code_chunks = [c for c in chunks if '```' in c.content]
        balanced = sum(1 for c in code_chunks if c.content.count('```') % 2 == 0)

        print(f"  Chunks: {len(chunks)}")
        print(f"  Code chunks: {len(code_chunks)}")
        print(f"  Balanced: {balanced}/{len(code_chunks) if code_chunks else 0}")

        if code_chunks and balanced == len(code_chunks):
            print(f"  ‚úÖ PASSED")
        elif not code_chunks:
            print(f"  ‚ö†Ô∏è  No code blocks")
        else:
            print(f"  ‚ùå FAILED: Unbalanced code fences")

    return True

def generate_validation_report():
    """Generate comprehensive validation report"""
    print_separator("COMPREHENSIVE VALIDATION REPORT")

    results = {
        'test_1': {'name': 'Code-Heavy Document (1000 tokens)', 'passed': False},
        'test_2': {'name': 'Reports Configuration (1500 tokens)', 'passed': False},
        'test_3': {'name': 'Edge Cases', 'passed': False}
    }

    # Run all tests
    try:
        results['test_1']['passed'] = test_code_heavy_document()
    except Exception as e:
        print(f"‚ùå Test 1 failed with error: {e}")
        import traceback
        traceback.print_exc()

    try:
        results['test_2']['passed'] = test_reports_configuration()
    except Exception as e:
        print(f"‚ùå Test 2 failed with error: {e}")
        import traceback
        traceback.print_exc()

    try:
        results['test_3']['passed'] = test_edge_cases()
    except Exception as e:
        print(f"‚ùå Test 3 failed with error: {e}")
        import traceback
        traceback.print_exc()

    # Summary
    print_separator("FINAL SUMMARY")

    passed = sum(1 for r in results.values() if r['passed'])
    total = len(results)

    print(f"üìä Test Results: {passed}/{total} passed")
    print()

    for test_id, result in results.items():
        status = "‚úÖ PASSED" if result['passed'] else "‚ùå FAILED"
        print(f"  {status} - {result['name']}")

    print()

    if passed == total:
        print("üéâ ALL TESTS PASSED!")
        print("\n‚úÖ Implementation Validation:")
        print("  ‚Ä¢ 2-stage approach implemented correctly")
        print("  ‚Ä¢ ExperimentalMarkdownSyntaxTextSplitter working")
        print("  ‚Ä¢ Code-aware separators functioning")
        print("  ‚Ä¢ Code integrity validation passing")
        print("  ‚Ä¢ Enhanced metadata being added")
        print("  ‚Ä¢ No artificial minimum size enforcement")
        return True
    else:
        print("‚ö†Ô∏è  SOME TESTS FAILED - Review implementation")
        return False

if __name__ == "__main__":
    print("üß™ Vector Memory Chunking Validation")
    print("Testing 2-stage code-aware chunking implementation")

    success = generate_validation_report()

    # Check debug log
    debug_log = Path("/tmp/vector_memory_debug.log")
    if debug_log.exists():
        print_separator("DEBUG LOG LOCATION")
        print(f"üìù Debug log available at: {debug_log}")
        print(f"   View with: tail -f {debug_log}")

    sys.exit(0 if success else 1)
